{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLvtm9cCTcme",
        "outputId": "03159f7c-699f-438f-9ed9-8a4a785d35f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n"
      ],
      "metadata": {
        "id": "I_tIJcPrTv8g"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainData = pd.read_csv(\"/content/drive/MyDrive/NLP/train.csv\")\n",
        "testData = pd.read_csv(\"/content/drive/MyDrive/NLP/test.csv\")\n",
        "del trainData[\"Id\"]\n",
        "del testData[\"Id\"]"
      ],
      "metadata": {
        "id": "7La0DJE1T4yX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stop_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epaELEMXe38D",
        "outputId": "029b7d52-34ff-4eaf-9efa-8e3adb6b636c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: stop_words in /usr/local/lib/python3.7/dist-packages (2018.7.23)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "from nltk.corpus import movie_reviews\n",
        "nltk.download('movie_reviews')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "import random\n",
        "from nltk.tokenize import word_tokenize \n",
        "from nltk.corpus import stopwords\n",
        "from stop_words import get_stop_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Az6O60RYUyzZ",
        "outputId": "8eee156c-a259-4ea5-e509-16bfb9b32ab7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pronuns = [\"a\",\"about\",\"above\",\"after\",\"again\",\"against\",\"all\",\"am\",\"an\",\"and\",\"any\",\"are\",\"aren’t\",\"as\",\n",
        "           \"at\",\"be\",\"because\",\"been\",\"before\",\"being\",\"below\",\"between\",\"both\",\"but\",\"by\",\"can’t\",\"cannot\"\n",
        "           ,\"could\",\"couldn’t\",\"did\",\"didn’t\",\"do\",\"does\",\"doesn’t\",\"doing\",\"don’t\",\"down\",\"during\",\"each\",\n",
        "           \"few\",\"for\",\"from\",\"further\",\"had\",\"hadn’t\",\"has\",\"hasn’t\",\"have\",\"haven’t\",\"having\",\"he\",\"he’d\"\n",
        "           ,\"he’ll\",\"he’s\",\"her\",\"here\",\"here’s\",\"hers\",\"herself\",\"him\",\"himself\",\"his\",\"how\",\"how’s\",\"i\"\n",
        "           ,\"i’d\",\"i’ll\",\"i’m\",\"i’ve\",\"if\",\"in\",\"into\",\"is\",\"isn’t\",\"it\",\"it’s\",\"its\",\"itself\",\"let’s\",\"me\"\n",
        "           ,\"more\",\"most\",\"mustn’t\",\"my\",\"myself\",\"no\",\"nor\",\"not\",\"of\",\"off\",\"on\",\"once\",\"only\",\"or\",\"other\"\n",
        "           ,\"ought\",\"our\",\"oursourselves\",\"out\",\"over\",\"own\",\"same\",\"shan’t\",\"she\",\"she’d\",\"she’ll\",\"she’s\"\n",
        "           ,\"should\",\"shouldn’t\",\"so\",\"some\",\"such\",\"than\",\"that\",\"that’s\",\"the\",\"their\",\"theirs\",\"them\"\n",
        "           ,\"themselves\",\"then\",\"there\",\"there’s\",\"these\",\"they\",\"they’d\",\"they’ll\",\"they’re\",\"they’ve\"\n",
        "           ,\"this\",\"those\",\"through\",\"to\",\"too\",\"under\",\"until\",\"up\",\"very\",\"was\",\"wasn’t\",\"we\",\"we’d\"\n",
        "           ,\"we’ll\",\"we’re\",\"we’ve\",\"were\",\"weren’t\",\"what\",\"what’s\",\"when\",\"when’s\",\"where\",\"where’s\"\n",
        "           ,\"which\",\"while\",\"who\",\"who’s\",\"whom\",\"why\",\"why’s\",\"with\",\"won’t\",\"would\",\"wouldn’t\",\"you\"\n",
        "           ,\"you’d\",\"you’ll\",\"you’re\",\"you’ve\",\"your\",\"yours\",\"yourself\",\"yourselves\"]\n",
        "pronuns_slang = [\"a\",\"about\",\"above\",\"after\",\"again\",\"against\",\"all\",\"am\",\"an\",\"and\",\"any\"\n",
        "                ,\"are\",\"arent\",\"as\",\"at\",\"be\",\"because\",\"been\",\"before\",\"being\",\"below\",\"between\",\"both\"\n",
        "                ,\"but\",\"by\",\"cant\",\"cannot\",\"could\",\"couldnt\",\"did\",\"didnt\",\"do\",\"does\",\"doesnt\",\"doing\"\n",
        "                ,\"dont\",\"down\",\"during\",\"each\",\"few\",\"for\",\"from\",\"further\",\"had\",\"hadnt\",\"has\",\"hasnt\"\n",
        "                ,\"have\",\"havent\",\"having\",\"he\",\"hed\",\"hell\",\"hes\",\"her\",\"here\",\"heres\",\"hers\",\"herself\"\n",
        "                ,\"him\",\"himself\",\"his\",\"how\",\"hows\",\"i\",\"id\",\"ill\",\"im\",\"ive\",\"if\",\"in\",\"into\",\"is\",\"isnt\"\n",
        "                ,\"it\",\"its\",\"its\",\"itself\",\"lets\",\"me\",\"more\",\"most\",\"mustnt\",\"my\",\"myself\",\"no\",\"nor\",\"not\"\n",
        "                ,\"of\",\"off\",\"on\",\"once\",\"only\",\"or\",\"other\",\"ought\",\"our\",\"oursourselves\",\"out\",\"over\",\"own\"\n",
        "                ,\"same\",\"shant\",\"she\",\"shed\",\"shell\",\"shes\",\"should\",\"shouldnt\",\"so\",\"some\",\"such\",\"than\"\n",
        "                ,\"that\",\"thats\",\"the\",\"their\",\"theirs\",\"them\",\"themselves\",\"then\",\"there\",\"theres\",\"these\"\n",
        "                ,\"they\",\"theyd\",\"theyll\",\"theyre\",\"theyve\",\"this\",\"those\",\"through\",\"to\",\"too\",\"under\",\"until\"\n",
        "                ,\"up\",\"very\",\"was\",\"wasnt\",\"we\",\"wed\",\"well\",\"were\",\"weve\",\"were\",\"werent\",\"what\",\"whats\",\"when\"\n",
        "                ,\"whens\",\"where\",\"wheres\",\"which\",\"while\",\"who\",\"whos\",\"whom\",\"why\",\"whys\",\"with\",\"wont\",\"would\",\n",
        "                \"wouldnt\",\"you\",\"youd\",\"youll\",\"youre\",\"youve\",\"your\",\"yours\",\"yourself\",\"yourselves\"]\n",
        "\n",
        "\n",
        "pronuns = list(set(pronuns + pronuns_slang))\n",
        "\n",
        "stw = list(get_stop_words('en')) + ['.',',',';','/','-','_',\"a\"] + list(stopwords.words('english')) + pronuns\n",
        "\n"
      ],
      "metadata": {
        "id": "WYFF0YzpWUSV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import string\n",
        "\n",
        "\n",
        "trainData['comment_without_sw'] = trainData['Comment'].apply(lambda x: ' '.join([word.translate(str.maketrans('', '', string.punctuation)).strip().lower() for word in x.split() \n",
        "if word.translate(str.maketrans('', '', string.punctuation)).strip().lower() not in (stw)]))"
      ],
      "metadata": {
        "id": "CMu-8ZVopRHT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testData['comment_without_sw'] = testData['Comment'].apply(lambda x: ' '.join([word.translate(str.maketrans('', '', string.punctuation)).strip().lower() for word in x.split() \n",
        "if word.translate(str.maketrans('', '', string.punctuation)).strip().lower() not in (stw)]))"
      ],
      "metadata": {
        "id": "-HNxQIIhGHUJ"
      },
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "v = TfidfVectorizer()\n",
        "x = v.fit_transform(trainData['comment_without_sw'])"
      ],
      "metadata": {
        "id": "IBYOfk3aiCX6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "x.toarray().shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYWx-1e5iI5M",
        "outputId": "d71cb4c7-cbc6-44a4-f410-d8ac34dfc53a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8695, 20060)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "freq = pd.Series(' '.join(trainData.comment_without_sw).split()).value_counts()\n",
        "N = 5\n",
        "freq[\"things\"]\n",
        "size = len(trainData)\n",
        "freq = freq[N < freq]\n",
        "freq = freq[freq < 85]\n",
        "\n",
        "freq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfcGVZJVrxBs",
        "outputId": "d830310c-c252-42a0-c8bf-535e570e5056"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "protein            84\n",
              "concentration      84\n",
              "times              84\n",
              "low                84\n",
              "higher             84\n",
              "                   ..\n",
              "replies             6\n",
              "straightforward     6\n",
              "shorts              6\n",
              "tissues             6\n",
              "wording             6\n",
              "Length: 3418, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.test.utils import common_texts\n",
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "id": "szpBTM3OVK-h"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "path = api.load(\"glove-wiki-gigaword-50\", return_path=True)\n",
        "print(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjQzP4MU1pvm",
        "outputId": "115605b0-1669-4750-c02b-521ade9b6207"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/gensim-data/glove-wiki-gigaword-50/glove-wiki-gigaword-50.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = api.load(\"glove-wiki-gigaword-50\")"
      ],
      "metadata": {
        "id": "FGdqHF4u4V1-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector = model[\"einstein\"]\n",
        "approximate_neighbors = model.most_similar([vector], topn=11)\n",
        "\n",
        "print(\"Approximate Neighbors\")\n",
        "for neighbor in approximate_neighbors:\n",
        "    print(neighbor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GombOMlM7-Ch",
        "outputId": "0da524e1-fcb5-4be9-9b0f-0dcf88fb835a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Approximate Neighbors\n",
            "('einstein', 1.0)\n",
            "('relativity', 0.7438952922821045)\n",
            "('bohr', 0.7286733388900757)\n",
            "('physics', 0.7018452882766724)\n",
            "('heisenberg', 0.7005619406700134)\n",
            "('freud', 0.6971668601036072)\n",
            "('theory', 0.6945189833641052)\n",
            "('leibniz', 0.6941564679145813)\n",
            "('mathematical', 0.6708714365959167)\n",
            "('invented', 0.6495018601417542)\n",
            "('goethe', 0.6423683166503906)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "freq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdMrTyY1Hrfs",
        "outputId": "cdf576f4-6237-4a43-cfb7-cb4fd43789c4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "protein            84\n",
              "concentration      84\n",
              "times              84\n",
              "low                84\n",
              "higher             84\n",
              "                   ..\n",
              "replies             6\n",
              "straightforward     6\n",
              "shorts              6\n",
              "tissues             6\n",
              "wording             6\n",
              "Length: 3418, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install annoy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "529tDmT9LrTz",
        "outputId": "dd39e27a-bd0c-4cc7-a96e-6bb28f8a4889"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: annoy in /usr/local/lib/python3.7/dist-packages (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.similarities.index import AnnoyIndexer\n",
        "\n",
        "# 100 trees are being used in this example\n",
        "annoy_index = AnnoyIndexer(model, 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBDlMQ_t5yS8",
        "outputId": "9ab6e95e-d410-402d-b3e3-3799c8987eb1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/similarities/index.py:180: FutureWarning: The default argument for metric will be removed in future version of Annoy. Please pass metric='angular' explicitly.\n",
            "  index = AnnoyIndex(num_features)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "approximate_neighbors = model.most_similar(\"cat\", topn=11, indexer=annoy_index)\n",
        "# Neatly print the approximate_neighbors and their corresponding cosine similarity values\n",
        "print(\"Approximate Neighbors\")\n",
        "for neighbor in approximate_neighbors:\n",
        "    print(neighbor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGEN0AQr6FzS",
        "outputId": "f6b5ccec-d5bf-4489-8002-68bc16980f2a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Approximate Neighbors\n",
            "('cat', 1.0)\n",
            "('dog', 0.8022635728120804)\n",
            "('rabbit', 0.7250292301177979)\n",
            "('cats', 0.6732944548130035)\n",
            "('dogs', 0.6680222451686859)\n",
            "('pig', 0.6426196098327637)\n",
            "('bug', 0.6370916366577148)\n",
            "('elephant', 0.636787474155426)\n",
            "('dragon', 0.6212137043476105)\n",
            "('duck', 0.6148057579994202)\n",
            "('horse', 0.6138353645801544)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "freq_sub = freq\n",
        "for key in freq_sub.keys():\n",
        "  if not key in model.vocab:\n",
        "    continue\n",
        "  for similiar in model.most_similar([model[key]], topn=11,indexer=annoy_index):\n",
        "    if (similiar[0] != key) and (similiar[0] in freq_sub.keys()):\n",
        "      freq_sub = freq_sub.drop(similiar[0])"
      ],
      "metadata": {
        "id": "m45JuwLI-2Fj"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 for 67 mb model"
      ],
      "metadata": {
        "id": "Wkw7EJXD1pCV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5:30 for 257 mb model"
      ],
      "metadata": {
        "id": "nuhNVQFDMarM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "freq_sub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mx9B7tYrBeE8",
        "outputId": "ec9343ca-8db9-466b-d830-360805015016"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "mrna               79\n",
              "person             73\n",
              "deleted            70\n",
              "universe           65\n",
              "amino              62\n",
              "                   ..\n",
              "ii                  6\n",
              "replies             6\n",
              "straightforward     6\n",
              "shorts              6\n",
              "wording             6\n",
              "Length: 691, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = model.most_similar([model[key]], topn=11,indexer=annoy_index)\n",
        "\n",
        "list(np.array(words)[:,0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8olaStXCTXZF",
        "outputId": "0b552bc6-0e1b-4e2f-d6c6-cbbad4850fb6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['wording',\n",
              " 'specifying',\n",
              " 'resolution',\n",
              " 'spelled',\n",
              " 'debated',\n",
              " 'ratification',\n",
              " 'timetable',\n",
              " 'resolutions',\n",
              " 'revise',\n",
              " 'omitted',\n",
              " 'timeframe']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(trainData[\"comment_without_sw\"][0])\n",
        "not set([\"negativ\"]).isdisjoint(set(trainData[\"comment_without_sw\"][0].split()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Km0Vu3wh3POc",
        "outputId": "ad301fec-afe1-4a49-aa2a-f3080ba8ca28"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "things might negative frequency dependent selection going least common phenotype reflected genotype going advantage environment instance prey animal vole light dark phenotype predator might recognize common phenotype food light voles common foxes may keeping closer eye light phenotypic voles recognising good prey reduce light causing alleles due increased predation dark genotypes increase proportion population scenario reversed cycle continues perpetually nnhowever unlikely strictly yearly usually takes time year entire populations allele frequencies change enough make large enough difference alter fitness nnmore likely year year basis population experiencing fluctuating selection alternating conditions environment favor one genotype another perhaps plant species living area flooded every year two phenotypes population plants much better dryer year one better wet year flooding drytype genotype fitness leading offspring therefore dry alleles population however flooded years wetliking phenotype better propagate wet genes\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def create_vector_from_comment(data):\n",
        "  feature_vectors = []\n",
        "  for comment in data['comment_without_sw']:\n",
        "    vector = []\n",
        "    for key in freq_sub.keys():\n",
        "      words = [key]\n",
        "      similar = None\n",
        "      if key in model.vocab:\n",
        "        sim = model.most_similar([model[key]], topn=11,indexer=annoy_index)\n",
        "        similar = list(np.array(sim)[:,0])\n",
        "      if(similar is not None):\n",
        "          words += similar\n",
        "      if not set(words).isdisjoint(set(comment.split())):\n",
        "        vector.append(1)\n",
        "      else:\n",
        "        vector.append(0)\n",
        "    feature_vectors.append(vector)\n",
        "\n",
        "  return feature_vectors"
      ],
      "metadata": {
        "id": "aOq_EqHnK2Ia"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_vectors = create_vector_from_comment(trainData)\n"
      ],
      "metadata": {
        "id": "B6eUPFSERjo_"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "13 min"
      ],
      "metadata": {
        "id": "Hy15SsAUPKCO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fv = np.array(feature_vectors)"
      ],
      "metadata": {
        "id": "SqbA-s_a-xax"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.where(fv[10] == 1))\n",
        "indices = np.where(fv[10] == 1)\n",
        "print(freq_sub.iloc[indices])\n",
        "print(trainData[\"Comment\"][10])\n",
        "\n",
        "words = model.most_similar(\"amino\", topn=11,indexer=annoy_index)\n",
        "\n",
        "list(np.array(words)[:,0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SRB25oO-_cd",
        "outputId": "598dfea5-fc6f-4d3d-930d-ea0723d17cac"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([  4,  41,  87, 118, 278, 282, 536]),)\n",
            "amino         62\n",
            "bunch         29\n",
            "labs          20\n",
            "wild          17\n",
            "titration     10\n",
            "hospital      10\n",
            "chloroform     6\n",
            "dtype: int64\n",
            " Is H2S what produced when the egg protein is being denatured? Then titration with a basic solution like NaOH would allow me to determine the amount of H2S, hence the amount of denatured protein. Is my thinking correct? It's a school lab so I don't have access to other fancy equipments :/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['amino',\n",
              " 'residues',\n",
              " 'protein',\n",
              " 'proteins',\n",
              " 'conserved',\n",
              " 'peptides',\n",
              " 'pathway',\n",
              " 'esters',\n",
              " 'receptors',\n",
              " 'specificity',\n",
              " 'receptor']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fv.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xwHQjt9Bn1L",
        "outputId": "a7803429-c593-4bb7-ea21-8504c8693f08"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8695, 691)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(freq_sub)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7VxQtuGCzob",
        "outputId": "75a434ce-ce45-48c6-9d6c-509b24b44600"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "691"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fv = np.array(feature_vectors)\n",
        "\n",
        "Y_labels = trainData[\"Topic\"].copy()\n",
        "\n",
        "counter = 0\n",
        "for x in fv:\n",
        "  if np.where(x == 1)[0].shape[0] == 0:\n",
        "    fv = np.delete(fv , x ,axis = 0)\n",
        "    Y_labels = Y_labels.drop(counter)\n",
        "  counter += 1\n",
        "fv = fv.astype(np.float64)"
      ],
      "metadata": {
        "id": "_5P5Z2SiHiDk"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(fv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93pC0oS2DvF7",
        "outputId": "781a8a29-20fb-444a-d1bd-fb85456752d4"
      },
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7456"
            ]
          },
          "metadata": {},
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "D = np.zeros((len(fv),len(fv)))"
      ],
      "metadata": {
        "id": "_9wcizLEdTPv"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D_curr = np.zeros((len(fv),len(fv)))"
      ],
      "metadata": {
        "id": "zUj85moNrIAa"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = 2500\n",
        "K = 3\n",
        "C_target = 3\n",
        "C_previous = len(fv)\n",
        "\n",
        "\n",
        "C_current = len(fv) // g \n",
        "\n",
        "\n",
        "\n",
        "Rk = np.zeros((len(fv) , K),dtype=int)"
      ],
      "metadata": {
        "id": "yYW36y8VB4yL"
      },
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "S8pSBKZDdI71"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fv.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gt4OMHpbWakL",
        "outputId": "31b5c7b7-acbb-41c5-baa7-335557a542be"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7456, 691)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numba\n",
        "\n",
        "@numba.jit(nopython=True,parallel=True)\n",
        "def calc_dist(vec1 , vec2):\n",
        "  return np.linalg.norm(vec1-vec2)"
      ],
      "metadata": {
        "id": "DxWONeTTFiwD"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_D_orginal():\n",
        "  for i in range(len(fv)):\n",
        "    sum = 0;\n",
        "    for j in range(i + 1, len(fv)):\n",
        "      D[i][j] = calc_dist(fv[i],fv[j])\n",
        "      D[j][i] = D[i][j]"
      ],
      "metadata": {
        "id": "BL7yt57tOWIA"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calc_D_orginal()\n",
        "# 3:33 min\n"
      ],
      "metadata": {
        "id": "ptzqSmdVPwmO"
      },
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_Rk():\n",
        "  for i in range(len(fv)):\n",
        "    result = np.argpartition(D[i], K)\n",
        "    Rk[i] = result[:K]\n",
        "\n"
      ],
      "metadata": {
        "id": "iMn0Tohkr0UC"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calc_Rk()\n"
      ],
      "metadata": {
        "id": "Tn8jBt9Fwlqp"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numba\n",
        "\n",
        "@numba.jit(nopython=True,parallel=True)\n",
        "def D_current(i, j):\n",
        "  sum = 0\n",
        "  for index1 in Rk[i]:\n",
        "    for index2 in Rk[j]:\n",
        "      sum += D[index1][index2]\n",
        "  return sum / math.pow(K+1,2)"
      ],
      "metadata": {
        "id": "LvYhLWCEKQyG"
      },
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#44 sec\n",
        "for i in range(len(fv)):\n",
        "  for j in range(i, len(fv)):\n",
        "    D_curr[i][j] = D_current(i,j)\n",
        "    D_curr[j][i] = D_curr[i][j] "
      ],
      "metadata": {
        "id": "dmlPoOgNKgpa"
      },
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numba\n",
        "\n",
        "@numba.jit(nopython=True,parallel=True)\n",
        "def find_first_key():\n",
        "  min_dist = np.inf\n",
        "  index = None\n",
        "  for i in range(len(fv)):\n",
        "    sum = 0\n",
        "    for j in range(len(fv)):\n",
        "      sum += D_curr[i][j]\n",
        "    if sum < min_dist:\n",
        "      min_dist = sum\n",
        "      index = i\n",
        "  return index"
      ],
      "metadata": {
        "id": "oFmpEBoGHn8h"
      },
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "S_current = set()\n",
        "# S_current.add(find_first_key())\n",
        "S_current"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5s7lvqnzJsBW",
        "outputId": "003f4f16-b90c-48b5-d6dc-c4b5eeb547ca"
      },
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{11}"
            ]
          },
          "metadata": {},
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install funcy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dO-gq09CUVoG",
        "outputId": "4b06197c-b387-4227-c262-a149734ba09d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.7/dist-packages (1.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from funcy import print_durations\n",
        "\n",
        "@numba.jit(nopython=True,parallel=True)\n",
        "def improved_argmax(all_vals):\n",
        "    return np.argmax(all_vals)"
      ],
      "metadata": {
        "id": "4bieaFevRlpt"
      },
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_rest_keys():\n",
        "\n",
        "  n = C_current - 1\n",
        "\n",
        "  all_vals = np.zeros(len(fv))\n",
        "  for i in range(n):\n",
        "    for j in range(len(fv)):\n",
        "      for key in S_current:\n",
        "        key_min = np.inf\n",
        "        if (j not in S_current):\n",
        "          distance = D_curr[key][j]\n",
        "          if(distance < key_min):\n",
        "            all_vals[j] = distance\n",
        "            key_min = distance\n",
        "    # idx = np.argmax(all_vals)\n",
        "    S_current.add(improved_argmax(all_vals))\n",
        "    all_vals = np.zeros(len(fv))\n",
        "\n",
        "\n",
        "\n",
        "      "
      ],
      "metadata": {
        "id": "JTiJlRjJNxpQ"
      },
      "execution_count": 241,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find_rest_keys()"
      ],
      "metadata": {
        "id": "EM_M8Prdau3k"
      },
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_keys():\n",
        "  S_current.append(find_first_key())\n",
        "  if C_target > 1:\n",
        "    find_rest_keys()"
      ],
      "metadata": {
        "id": "2dAy67WTLRAr"
      },
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36-b1z0iwp1p",
        "outputId": "8dcdcfe9-2c38-45c5-c11d-028d349dd3ed"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    1,    2, ..., 7453, 7454, 7455])"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_label():\n",
        "  for i in range(len(fv)):\n",
        "    min = np.inf\n",
        "    index = None\n",
        "    if(L[i] not in S_current):\n",
        "      for key in S_current:\n",
        "        if D_curr[L[i]][key] < min:\n",
        "          min = D_curr[L[i]][key]\n",
        "          index = key\n",
        "      L[i] = index"
      ],
      "metadata": {
        "id": "OlEHZaStM6eG"
      },
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# L = np.arange(len(fv))\n",
        "# MapL = []\n",
        "# find_label()\n",
        "# count = 0\n",
        "# for i in set(L):\n",
        "#   L = np.where(L == i,count,L)\n",
        "#   count += 1\n",
        "\n",
        "# for i in range(len(L)):\n",
        "#   MapL.append(np.where(L  == i))\n",
        "# print(MapL[3])\n",
        "#dataIndex = np.arange(len(fv))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WF5rypee1K3-",
        "outputId": "f33e981f-8c59-48f4-aeab-dbdf73cf61f5"
      },
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([6580]),)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "S_current"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sly6gyFKEFHG",
        "outputId": "b17467b2-4e2e-411b-8f50-f17af7329e63"
      },
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{11, 369, 2232, 6473, 6580}"
            ]
          },
          "metadata": {},
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numba\n",
        "\n",
        "@numba.jit(nopython=True,parallel=True)\n",
        "def calc_D_current(i,j,num1,num2):\n",
        "  sum = 0\n",
        "  for index1 in Rk[i]:\n",
        "    for index2 in Rk[j]:\n",
        "      sum += D[index1][index2]\n",
        "  return sum / (num1*num2)"
      ],
      "metadata": {
        "id": "YPHbk92XtHH4"
      },
      "execution_count": 244,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# P = np.zeros(C_current)\n",
        "# for i in range(np.amin(L),np.amax(L)):\n",
        "#    P[i] = np.count_nonzero(L == i)\n",
        "# P"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Xz4ijMKuPMF",
        "outputId": "66a8318d-d19d-40cd-974a-26a4575fb7d4"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., ..., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@numba.jit(nopython=True,parallel=True)\n",
        "def calc_D_current(v1, v2):\n",
        "  sum = 0\n",
        "  for index1 in v1:\n",
        "    for index2 in v2:\n",
        "      sum += D[index1][index2]\n",
        "  return sum / (len(v1)*len(v2))"
      ],
      "metadata": {
        "id": "ZXadLEMj08Uo"
      },
      "execution_count": 245,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# v1 = []\n",
        "# v2 = []\n",
        "# i = 1036\n",
        "# j = 2\n",
        "# v1.append(Rk[i])\n",
        "# v2.append(Rk[j])\n",
        "# if(L[i] != L[j]):\n",
        "#   v1.append(MapL[L[i]])\n",
        "#   v2.append(MapL[L[j]])\n",
        "#   v1 = np.unique(np.concatenate((v1[0],v1[1][0]),0))\n",
        "#   v2 = np.unique(np.concatenate((v2[0],v2[1][0]),0))\n",
        "\n",
        "\n",
        "# print(v1)\n",
        "# print(v2)\n",
        "# print(MapL[L[i]])\n",
        "# print(MapL[L[j]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZtca7E88Tuy",
        "outputId": "e185409e-d6ab-4154-8105-5b494aa1b9c5"
      },
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([0, 0, 0])]\n",
            "[array([0, 0, 0])]\n",
            "(array([   0,    1,    2, ..., 7453, 7454, 7455]),)\n",
            "(array([   0,    1,    2, ..., 7453, 7454, 7455]),)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for i in range(len(fv)):\n",
        "#   for j in range(len(fv)):\n",
        "#     v1 = []\n",
        "#     v2 = []\n",
        "#     v1.append(Rk[i])\n",
        "#     v2.append(Rk[j])\n",
        "#     if(L[i] != L[j]):\n",
        "#       v1.append(MapL[L[i]])\n",
        "#       v2.append(MapL[L[j]])\n",
        "#       v1 = np.unique(np.concatenate((v1[0],v1[1][0]),0))\n",
        "#       v2 = np.unique(np.concatenate((v2[0],v2[1][0]),0))\n",
        "#     else :\n",
        "#       v1 = np.unique(np.concatenate((v1[0],[]),0)).astype(np.int64)\n",
        "#       v2 = np.unique(np.concatenate((v2[0],[]),0)).astype(np.int64)\n",
        "#     D_curr[i][j] = calc_D_current(v1, v2)\n",
        "#     D_curr[i][j] = D_curr[j][i]\n",
        "#   print(i)"
      ],
      "metadata": {
        "id": "cDZFOHE46feb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while(C_current > C_target):\n",
        "  find_keys()\n",
        "  find_label()\n",
        "  count = 0\n",
        "  for i in set(L):\n",
        "    L = np.where(L == i,count,L)\n",
        "    count += 1\n",
        "  for i in range(len(L)):\n",
        "    MapL.append(np.where(L  == i))\n",
        "  \n",
        "\n",
        "  for i in range(len(fv)):\n",
        "    for j in range(len(fv)):\n",
        "      v1 = []\n",
        "      v2 = []\n",
        "      v1.append(Rk[i])\n",
        "      v2.append(Rk[j])\n",
        "      if(L[i] != L[j]):\n",
        "        v1.append(MapL[L[i]])\n",
        "        v2.append(MapL[L[j]])\n",
        "        v1 = np.unique(np.concatenate((v1[0],v1[1][0]),0))\n",
        "        v2 = np.unique(np.concatenate((v2[0],v2[1][0]),0))\n",
        "      D_curr[i][j] = calc_D_current(v1, v2)\n",
        "      D_curr[i][j] = D_curr[j][i]\n",
        "  C_current = C_current // g"
      ],
      "metadata": {
        "id": "S7LOEE90cpj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "find_keys()\n",
        "find_label()\n",
        "count = 0\n",
        "for i in set(L):\n",
        "  L = np.where(L == i,count,L)\n",
        "  count += 1\n",
        "print(L) #clustered"
      ],
      "metadata": {
        "id": "bv3Rm6dgFqTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mU_c8CgdJMyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_feature_vectors = create_vector_from_comment(testData)\n",
        "fv_test = np.array(test_feature_vectors)"
      ],
      "metadata": {
        "id": "YY7hTwpaF8YF"
      },
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(fv_test)):\n",
        "  correct = 0\n",
        "  min_dist = np.inf\n",
        "  index = None\n",
        "  for key in S_current:\n",
        "    distance = calc_dist(fv_test[i],key)\n",
        "    if distance < min:\n",
        "      min = distance\n",
        "      index = key\n",
        "  if(testData['comment_without_sw'][i].Topic == trainData['comment_without_sw'][index].Topic):\n",
        "    correct += 1\n",
        "\n",
        "print(correct/(len(fv_test))) #accuracy"
      ],
      "metadata": {
        "id": "hwK-4-CCH60g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}